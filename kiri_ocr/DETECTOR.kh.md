# ឯកសារសម្រាប់ Text Detector

## ទិដ្ឋភាពទូទៅ

ថ្នាក់ `TextDetector` គឺជាប្រព័ន្ធរាវរកអត្ថបទដែលមិនប្រកាន់ភាសា ដែលប្រើប្រាស់វិធីសាស្ត្រវិភាគប្លង់ទំព័ររបស់ Tesseract ។ វាស្វែងរកតំបន់អត្ថបទនៅក្នុងរូបភាពដោយស្វ័យប្រវត្តិ ដោយមិនគិតពីប្រភេទអក្សរ (អង់គ្លេស ខ្មែរ អារ៉ាប់ ចិន ។ល។) ដោយមិនតម្រូវឱ្យមានការកំណត់រចនាសម្ព័ន្ធសម្រាប់ភាសាជាក់លាក់ណាមួយឡើយ។

## លក្ខណៈពិសេសសំខាន់ៗ

* **មិនប្រកាន់ភាសា** ៖ រាវរកអត្ថបទក្នុងគ្រប់ភាសាដោយស្វ័យប្រវត្តិ
* **ទំហំសម្របខ្លួន** ៖ ដំណើរការជាមួយទាំងរូបភាពតូច និងឯកសារ A4 ធំ
* **ចន្លោះគែមស្វ័យប្រវត្តិ (Auto Padding)** ៖ គណនាចន្លោះគែមដែលសមស្របបំផុតដោយស្វ័យប្រវត្តិផ្អែកលើទំហំអត្ថបទ
* **ការដោះស្រាយស្រៈនិស្ស័យ/វណ្ណយុត្តិ** ៖ ដោះស្រាយបានយ៉ាងល្អជាមួយអក្សរដែលមានស្រៈនិងវណ្ណយុត្តិស្មុគស្មាញ (ដូចជាភាសាខ្មែរ)
* **ការរាវរកបន្ទាត់ និងពាក្យ** ៖ អាចរាវរកបានទាំងបន្ទាត់ពេញ និងពាក្យនីមួយៗ

---

## របៀបដែលវាដំណើរការ៖ មួយជំហានម្តងៗ

### ការចាប់ផ្តើម (Initialization)

```python
detector = TextDetector(padding=None)
```

**ប៉ារ៉ាម៉ែត្រ៖**

* `padding`៖ ជម្រើស។ ប្រសិនបើ `None` (លំនាំដើម) ចន្លោះគែមត្រូវបានគណនាដោយស្វ័យប្រវត្តិជា 15-20% នៃកម្ពស់អត្ថបទមធ្យម
* ប្រសិនបើបានបញ្ជាក់ វានឹងប្រើតម្លៃចន្លោះគែមថេរជាភីកសែល

---

## អាល់ហ្គោរីតរាវរកបន្ទាត់

### ជំហានទី 1៖ ការផ្ទុក និងរៀបចំរូបភាព

```python
img = cv2.imread(image_path)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
```

**អ្វីដែលកើតឡើង៖**

* ផ្ទុករូបភាពពីឯកសារ
* បំលែងទៅជាពណ៌ប្រផេះ (grayscale) សម្រាប់ការដំណើរការ
* រក្សាទុកវិមាត្ររូបភាព (កម្ពស់ ទទឹង)

---

### ជំហានទី 2៖ Otsu Binarization

```python
_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
```

**អ្វីដែលកើតឡើង៖**

* ប្រើវិធីសាស្ត្រ Otsu ដើម្បីស្វែងរកកម្រិតពន្លឺ (threshold) ដែលល្អបំផុតដោយស្វ័យប្រវត្តិ
* បំលែងពីពណ៌ប្រផេះទៅជាគោលពីរ (អត្ថបទពណ៌ខ្មៅលើផ្ទៃខាងក្រោយពណ៌ស)
* រាវរកប៉ូលដោយស្វ័យប្រវត្តិ៖ ប្រសិនបើលទ្ធផលភាគច្រើនជាពណ៌ស (>50%) វានឹងត្រឡប់ពណ៌វិញ (invert)

**ហេតុអ្វីប្រើ Otsu?**

* សម្របខ្លួនដោយស្វ័យប្រវត្តិទៅនឹងលក្ខខណ្ឌពន្លឺផ្សេងៗគ្នា
* មិនត្រូវការការកែសម្រួលកម្រិតពន្លឺដោយដៃ
* ដំណើរការបានល្អសម្រាប់រូបភាពឯកសារ

**ឧទាហរណ៍៖**

```
Input:  Gray image (0-255 values)
Output: Binary image (0 or 255 only)
        ■■■□□□□□  →  11100000
        Text becomes 1, background becomes 0
```

---

### ជំហានទី 3៖ ការវិភាគសមាសធាតុដែលតភ្ជាប់គ្នា (Connected Components Analysis)

```python
num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)
```

**អ្វីដែលកើតឡើង៖**

* ស្វែងរកភីកសែលពណ៌សដែលតភ្ជាប់គ្នាទាំងអស់ (តួអក្សរឬផ្នែកដែលមានសក្តានុពល)
* តំបន់ដែលតភ្ជាប់នីមួយៗទទួលបានលេខសម្គាល់តែមួយគត់
* គណស្ថិតិ៖ x, y, ទទឹង, កម្ពស់, ផ្ទៃក្រឡា, ចំណុចកណ្តាល (centroid)

**Connectivity=8 មានន័យថា៖**

```
A pixel connects to all 8 neighbors:
□ □ □
□ ■ □
□ □ □
```

**លទ្ធផលសម្រាប់សមាសធាតុនីមួយៗ៖**

* `x, y`៖ ទីតាំងជ្រុងខាងឆ្វេងផ្នែកខាងលើ
* `w, h`៖ ទទឹង និងកម្ពស់
* `area`៖ ចំនួនភីកសែលសរុបនៅក្នុងសមាសធាតុ
* `centroid`៖ ចំណុចកណ្តាល (x_center, y_center)

---

### ជំហានទី 4៖ ការច្រោះសំឡេងរំខានមូលដ្ឋាន

```python
if w >= 2 and h >= 3 and area >= 6:
    valid_components.append(component)
```

**អ្វីដែលកើតឡើង៖**

* លុបសំឡេងរំខានតូចៗទំហំ 1 ភីកសែល
* រក្សាសមាសធាតុដែលមានទំហំយ៉ាងតិច 2×3 ភីកសែល
* ផ្ទៃក្រឡាអប្បបរមា 6 ភីកសែល

**ហេតុអ្វីប្រើកម្រិតកំណត់ទាំងនេះ?**

* សូម្បីតែតួអក្សរតូចៗក៏មានយ៉ាងហោចណាស់ពីរបីភីកសែលដែរ
* សំឡេងរំខានមួយភីកសែលមិនដែលជាអត្ថបទទេ
* ការច្រោះដោយប្រុងប្រយ័ត្ន (មិនលុបអត្ថបទពិត)

---

### ជំហានទី 5៖ ការវិភាគស្ថិតិ - ស្វែងរកទំហំអត្ថបទមធ្យម (Median)

```python
median_height = np.median(heights)
median_width = np.median(widths)
```

**អ្វីដែលកើតឡើង៖**

* ប្រមូលកម្ពស់ និងទទឹងនៃសមាសធាតុត្រឹមត្រូវទាំងអស់
* គណនាមេដ្យាន (មិនមែនមធ្យមភាគ) ដើម្បីចៀសវាងតម្លៃខុសប្រក្រតី (outliers)
* ប្រើមេដ្យានជា "ទំហំតួអក្សរធម្មតា"

**ហេតុអ្វីប្រើមេដ្យានជំនួសឱ្យមធ្យមភាគ?**

```
Heights: [10, 12, 11, 10, 100, 12, 11]  ← One outlier (100)
Mean:    23.7  ← Skewed by outlier
Median:  11    ← Represents typical character ✓
```

**ការគណនាចន្លោះគែមស្វ័យប្រវត្តិ៖**

```python
auto_padding = max(2, int(median_height * 0.15))
```

* ចន្លោះគែម = 15% នៃកម្ពស់អត្ថបទធម្មតា
* អប្បបរមា 2 ភីកសែល
* ផ្លាស់ប្តូរទំហំដោយស្វ័យប្រវត្តិទៅតាមទំហំអត្ថបទ

---

### ជំហានទី 6៖ ការច្រោះសមាសធាតុកម្រិតខ្ពស់

```python
min_h = median_height * 0.25
max_h = median_height * 3.0
```

**ច្បាប់របស់ Tesseract ដែលបានអនុវត្ត៖**

1. **ការច្រោះកម្ពស់៖**

   * រក្សាទុក៖ 0.25× ដល់ 3× កម្ពស់មេដ្យាន
   * ឧទាហរណ៍៖ ប្រសិនបើមេដ្យាន = 20px រក្សាសមាសធាតុដែលមានកម្ពស់ 5-60px
   * លុប៖ សំឡេងរំខានតូចៗ និងវត្ថុធំៗដែលមិនមែនជាអត្ថបទ
2. **ការច្រោះទទឹង៖**

   * រក្សាទុក៖ យ៉ាងហោចណាស់ 10% នៃទទឹងមេដ្យាន
   * អតិបរមា៖ 95% នៃទទឹងរូបភាព
   * លុប៖ បន្ទាត់/ស៊ុមដែលមានទទឹងពេញ
3. **ការច្រោះសមាមាត្រ (Aspect Ratio)៖**

   ```python
   aspect = width / height
   if 0.05 < aspect < 20:
   ```

   * រក្សាទុក៖ តួអក្សរដែលមានសមាមាត្រសមហេតុផល
   * លុប៖ បន្ទាត់ស្តើងខ្លាំង ឬដុំធំទូលាយខ្លាំង
4. **ការច្រោះវណ្ណយុត្តិ (សម្រាប់ខ្មែរ/អារ៉ាប់/។ល។)៖**

   ```python
   if h >= median_height * 0.3:
   ```

   * ត្រូវមានយ៉ាងហោចណាស់ 30% នៃកម្ពស់មេដ្យាន
   * ច្រោះចេញនូវសញ្ញាស្រៈនិងវណ្ណយុត្តិដាច់ដោយឡែក
   * ពួកវានឹងត្រូវបានចាប់យកជាផ្នែកនៃប្រអប់តួអក្សរមេ

**ឧទាហរណ៍រូបភាព៖**

```
Before filtering:          After filtering:
■ (tiny noise)          
█ (small diacritic)     
███ (character) ✓         ███ ✓
███ (character) ✓         ███ ✓
▬▬▬▬▬ (line)            
█████████ (too wide)    
```

---

### ជំហានទី 7៖ ការស្វែងរកបន្ទាត់ (Baseline Clustering)

```python
text_components.sort(key=lambda c: c['centroid'][1])  # Sort by Y position
```

**អាល់ហ្គោរីត៖**

1. តម្រៀបសមាសធាតុទាំងអស់តាមទីតាំងបញ្ឈរ (ពីលើចុះក្រោម)
2. ចាប់ផ្តើមបន្ទាត់ដំបូងជាមួយសមាសធាតុដំបូង
3. សម្រាប់សមាសធាតុបន្ទាប់នីមួយៗ៖
   * គណនាចំណុចកណ្តាលបញ្ឈរនៃបន្ទាត់បច្ចុប្បន្ន
   * គណនាកម្ពស់មធ្យមនៃបន្ទាត់បច្ចុប្បន្ន
   * ប្រសិនបើសមាសធាតុថ្មីស្ថិតក្នុងកម្រិតអនុគ្រោះ (tolerance) បន្ថែមទៅបន្ទាត់បច្ចុប្បន្ន
   * បើមិនដូច្នេះទេ ចាប់ផ្តើមបន្ទាត់ថ្មី

**ការគណនាកម្រិតអនុគ្រោះ៖**

```python
tolerance = avg_line_height * 0.45
```

**ហេតុអ្វី 0.45 (45%)?**

* តឹងរ៉ឹងគ្រប់គ្រាន់ដើម្បីបំបែកបន្ទាត់ផ្សេងគ្នា
* ធូររលុងគ្រប់គ្រាន់ដើម្បីដោះស្រាយការប្រែប្រួលនៃបន្ទាត់មូលដ្ឋាន (baseline)
* គិតគូរពីតួអក្សរដែលមានជើងចុះក្រោម (ដូចជា g, y, p)

**ឧទាហរណ៍រូបភាព៖**

```
Line 1: Hello World    ← Components at Y ≈ 100
        (tolerance: ±20px)
                        ← Gap (no components at Y ≈ 150)
Line 2: Next line      ← Components at Y ≈ 200
```

**អ្វីដែលត្រូវបានដាក់ជាក្រុមជាមួយគ្នា៖**

```
H e l l o   ← All centroids within 100 ± 20
W o r l d   ← Same line (Y ≈ 95-105)

N e x t     ← New line (Y ≈ 200, far from 100)
```

---

### ជំហានទី 8៖ បង្កើតប្រអប់ដែលហ៊ុំព័ទ្ធបន្ទាត់ (Line Bounding Boxes)

```python
x_min = min(c['bbox'][0] for c in line)
y_min = min(c['bbox'][1] for c in line)
x_max = max(c['bbox'][0] + c['bbox'][2] for c in line)
y_max = max(c['bbox'][1] + c['bbox'][3] for c in line)
```

**អ្វីដែលកើតឡើង៖**

* សម្រាប់បន្ទាត់នីមួយៗ ស្វែងរកប្រអប់ដែលហ៊ុំព័ទ្ធសមាសធាតុទាំងអស់
* យក x ឆ្វេងបំផុត, y លើបំផុត, x ស្ដាំបំផុត, y ក្រោមបំផុត
* បង្កើតចតុកោណកែងដែលគ្របដណ្តប់បន្ទាត់ទាំងមូល

**រូបភាព៖**

```
Components in line:    Bounding box:
█ ██ █ █              ┌─────────────┐
                      │█ ██ █ █     │
                      └─────────────┘
```

**បន្ថែមចន្លោះគែម (Padding)៖**

```python
x_pad = max(0, x_min - padding)
y_pad = max(0, y_min - padding)
w_pad = min(img_w - x_pad, width + 2 * padding)
h_pad = min(img_h - y_pad, height + 2 * padding)
```

* បន្ថែមចន្លោះគែមគ្រប់ជ្រុង
* ធានាថាប្រអប់ស្ថិតនៅក្នុងព្រំដែនរូបភាព
* ចាប់យកតួអក្សរនៅគែមបានយ៉ាងពេញលេញ

---

### ជំហានទី 9៖ បញ្ចូលប្រអប់ដែលត្រួតលើគ្នា (Merge Overlapping Boxes)

```python
def _merge_overlapping_boxes(boxes, median_height):
```

**បញ្ហា៖** ជួនកាលបន្ទាត់តែមួយត្រូវបានរាវរកឃើញច្រើនដង

**ដំណោះស្រាយ៖**

1. តម្រៀបប្រអប់តាមទីតាំង Y
2. ប្រៀបធៀបប្រអប់ដែលជាប់គ្នា
3. គណនាការត្រួតលើគ្នាផ្នែកបញ្ឈរ
4. ប្រសិនបើការត្រួតលើគ្នា > 40% នៃកម្ពស់ប្រអប់តូចជាង → បញ្ចូលគ្នា
5. បើមិនដូច្នេះទេ → រក្សាទុកជាបន្ទាត់ដាច់ដោយឡែក

**ការគណនាការត្រួតលើគ្នា៖**

```python
overlap = max(0, min(y2_box1, y2_box2) - max(y1_box1, y1_box2))
```

**ឧទាហរណ៍រូបភាព៖**

```
Box 1: ████████
Box 2:   ████████   ← 60% overlap → MERGE

Result: ████████████
```

```
Box 1: ████████
                    ← Small gap
Box 2:     ████████ ← 20% overlap → KEEP SEPARATE
```

---

### ជំហានទី 10៖ តម្រៀប និងត្រឡប់លទ្ធផល

```python
line_boxes = sorted(line_boxes, key=lambda b: b[1])
```

**អ្វីដែលកើតឡើង៖**

* តម្រៀបប្រអប់ទាំងអស់ពីលើចុះក្រោម (តាមកូអរដោនេ Y)
* ត្រឡប់បញ្ជីនៃ tuples (x, y, ទទឹង, កម្ពស់)
* លំដាប់នៃការអាន៖ ពីលើចុះក្រោម

---

## អាល់ហ្គោរីតរាវរកពាក្យ

ការរាវរកពាក្យអនុវត្តតាមជំហានស្រដៀងគ្នា ប៉ុន្តែមានតក្កវិជ្ជាដាក់ក្រុមផ្សេងគ្នា៖

### ភាពខុសគ្នាពីការរាវរកបន្ទាត់៖

1. **ជំហានដំបូងដូចគ្នា** (1-6)៖ Binarization, សមាសធាតុ, ការច្រោះ
2. **ការដាក់ក្រុមបន្ទាត់** (ជំហានទី 7)៖ ដាក់ក្រុមសមាសធាតុជាបន្ទាត់សិន
3. **ការវិភាគគម្លាតផ្ដេក** ៖

```python
   word_gap = median_char_width * 0.6
```

* គណនាទទឹងតួអក្សរធម្មតា
* គម្លាតរវាងពាក្យ > 0.6× ទទឹងតួអក្សរ
* គម្លាតក្នុងពាក្យ < 0.6× ទទឹងតួអក្សរ

1. **ការបែងចែកពាក្យ** ៖

```python
   gap = next_char_x - (prev_char_x + prev_char_width)
   if gap <= word_gap:
       same_word()
   else:
       new_word()
```

**ឧទាហរណ៍រូបភាព៖**

```
H e l l o   W o r l d
^^^^^^      ^^^^^^      Character gaps (small)
      ^^^^^             Word gap (large) ← Split here!
    
Words: ["Hello", "World"]
```

---

## ប៉ារ៉ាម៉ែត្រសំខាន់ៗ និងឥទ្ធិពលរបស់វា

### ការច្រោះសមាសធាតុ

| Parameter        | Value                   | Effect                                |
| ---------------- | ----------------------- | ------------------------------------- |
| Min height       | `0.25 × median`      | Remove noise smaller than 25% of text |
| Max height       | `3.0 × median`       | Remove large blobs/lines              |
| Min width        | `0.1 × median`       | Remove tiny specks                    |
| Max width        | `0.95 × image_width` | Remove full-width lines               |
| Aspect ratio     | `0.05 - 20`           | Keep reasonable character shapes      |
| Diacritic filter | `≥ 0.3 × median`    | Remove isolated vowel marks           |

### ការដាក់ក្រុមបន្ទាត់

| Parameter     | Value                   | Purpose                                       |
| ------------- | ----------------------- | --------------------------------------------- |
| Tolerance     | `0.45 × line_height` | Balance line separation vs baseline variation |
| Overlap merge | `> 0.4 × min_height` | Merge duplicate detections                    |

### ចន្លោះគែម (Padding)

| Type   | Value                     | When to use                   |
| ------ | ------------------------- | ----------------------------- |
| Auto   | `0.15 × median_height` | Default (recommended)         |
| Custom | User-specified            | Special cases, manual control |

---

## ភាពស្មុគស្មាញនៃអាល់ហ្គោរីត

**Time Complexity:**

* Connected components: O(n) ដែល n = ចំនួនភីកសែល
* Sorting: O(k log k) ដែល k = ចំនួនសមាសធាតុ
* Line grouping: O(k) ឆ្លងកាត់តែម្តង
* សរុប៖ **O(n + k log k)** - លឿនណាស់!

**Space Complexity:**

* រក្សាទុកសមាសធាតុទាំងអស់៖ O(k)
* រូបភាពគោលពីរ៖ O(n)
* សរុប៖ **O(n + k)** - សន្សំសំចៃអង្គចងចាំ

---

## គុណសម្បត្តិនៃវិធីសាស្ត្រនេះ

1. **មិនប្រកាន់ភាសា** ៖ មិនត្រូវការគំរូភាសា
2. **លឿន** ៖ Computer vision សុទ្ធ, មិនមាន deep learning inference
3. **ត្រឹមត្រូវ** ៖ ផ្អែកលើអាល់ហ្គោរីតដែលបានបញ្ជាក់របស់ Tesseract
4. **សម្របខ្លួន** ៖ ដំណើរការលើគ្រប់ទំហំរូបភាពដោយស្វ័យប្រវត្តិ
5. **រឹងមាំ** ៖ ដោះស្រាយសំឡេងរំខាន, ពន្លឺប្រែប្រួល, អក្សរស្មុគស្មាញ
6. **សាមញ្ញ** ៖ មិនត្រូវការទិន្នន័យបណ្តុះបណ្តាល ឬ GPU

---

## ករណីប្រើប្រាស់ទូទៅ

### អត្ថបទបន្ទាត់តែមួយ (ឧ. ស្លាក, ចំណងជើងរូបភាព)

```python
detector = TextDetector()
boxes = detector.detect_lines("single_line.png")
# Returns: [(x, y, w, h)]  ← One box
```

### ឯកសារច្រើនបន្ទាត់ (ឧ. កថាខណ្ឌ, ទំព័រ A4)

```python
detector = TextDetector()
boxes = detector.detect_lines("document.png")
# Returns: [(x1,y1,w1,h1), (x2,y2,w2,h2), ...]  ← Multiple boxes
```

### ការរាវរកកម្រិតពាក្យ (ឧ. វាលទម្រង់)

```python
detector = TextDetector()
words = detector.detect_words("form.png")
# Returns: [(x1,y1,w1,h1), ...] for each word
```

### ចន្លោះគែមផ្ទាល់ខ្លួន

```python
detector = TextDetector(padding=5)  # Force 5px padding
boxes = detector.detect_lines("image.png")
```

---

## ការដោះស្រាយបញ្ហា

### បញ្ហា៖ បាត់អត្ថបទតូចៗ

**ដំណោះស្រាយ៖** អត្ថបទអាចត្រូវបានច្រោះចេញជាសំឡេងរំខាន

* ពិនិត្យមើលថាតើកម្ពស់អត្ថបទ > 30% នៃមេដ្យាន
* កាត់បន្ថយកម្រិតកំណត់នៃការច្រោះវណ្ណយុត្តិ

### បញ្ហា៖ បន្ទាត់បញ្ចូលគ្នា

**ដំណោះស្រាយ៖** កម្រិតអនុគ្រោះធូររលុងពេក

* បច្ចុប្បន្ន៖ 0.45 × កម្ពស់បន្ទាត់
* សាកល្បងកាត់បន្ថយមក 0.35 ឬ 0.30

### បញ្ហា៖ ប្រអប់តូចៗច្រើនពេក

**ដំណោះស្រាយ៖** វណ្ណយុត្តិត្រូវបានរាវរកឃើញថាជាបន្ទាត់

* បង្កើនការច្រោះវណ្ណយុត្តិ (0.3 → 0.4)
* ពិនិត្យគុណភាព binarization

### បញ្ហា៖ អត្ថបទដាច់នៅគែម

**ដំណោះស្រាយ៖** ចន្លោះគែមមិនគ្រប់គ្រាន់

* បង្កើនចន្លោះគែមស្វ័យប្រវត្តិ (0.15 → 0.20)
* ឬប្រើចន្លោះគែមដោយដៃ៖ `TextDetector(padding=10)`

---

## ព័ត៌មានលម្អិតបច្ចេកទេស

### ហេតុអ្វីប្រើ Connected Components?

**ជម្រើសផ្សេងទៀត៖**

* Contours៖ ស្មុគស្មាញជាង, យឺតជាង
* Deep learning៖ ត្រូវការ GPU, ទិន្នន័យបណ្តុះបណ្តាល
* Template matching៖ ជាក់លាក់សម្រាប់ភាសា

**គុណសម្បត្តិ៖**

* លឿន៖ ឆ្លងកាត់រូបភាពតែមួយដង
* សាមញ្ញ៖ ការតំណាងអត្ថបទតាមធម្មជាតិ
* ត្រឹមត្រូវ៖ ចាប់យកបណ្តុំភីកសែលបានជាក់លាក់

### ហេតុអ្វីប្រើស្ថិតិមេដ្យាន?

**ភាពរឹងមាំ៖**

```python
# Image with mostly 12px text + one 100px title
heights = [12, 11, 13, 12, 100, 12, 11]

mean = 24.4    # Skewed by title
median = 12    # True character size ✓
```

### ហេតុអ្វីប្រើ 8-connectivity?

```
4-connectivity:       8-connectivity:
    □                 □ □ □
  □ ■ □             □ ■ □
    □                 □ □ □
```

8-connectivity ចាប់យកការតភ្ជាប់អង្កត់ទ្រូង ដែលសំខាន់សម្រាប់អត្ថបទទ្រេត និងអក្សរឆ្លាក់។

---

## ការកែលម្អនាពេលអនាគត

ការកែលម្អដែលអាចធ្វើបាន៖

1. ការរាវរកនិងកែតម្រូវការបង្វិល
2. ការកែតម្រូវភាពវៀចសម្រាប់ឯកសារស្កេន
3. ការរាវរកប្លង់ច្រើនជួរឈរ
4. ការទទួលស្គាល់រចនាសម្ព័ន្ធតារាង
5. តំបន់អត្ថបទតាមឋានានុក្រម (ចំណងជើង, កថាខណ្ឌ, ចំណងជើងរូបភាព)

---

## ឯកសារយោង

* ផ្អែកលើការវិភាគប្លង់ទំព័ររបស់ Tesseract OCR
* ប្រើប្រាស់អាល់ហ្គោរីត connected components របស់ OpenCV
* ត្រូវបានបំផុសគំនិតដោយឯកសារស្រាវជ្រាវការវិភាគឯកសារ

## អាជ្ញាប័ណ្ណ

ជាផ្នែកនៃប្រព័ន្ធ Kiri OCR
